{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12495,"status":"ok","timestamp":1742583163188,"user":{"displayName":"Rao Family","userId":"03614244497955458674"},"user_tz":-330},"id":"VSCkbX3JPtMa","outputId":"14c41df5-0feb-40d6-ef2e-8fbb5cd511aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","import sys\n","import torch\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vf_fWR7DQGWn"},"outputs":[],"source":["ROOT_DIR = \"proj_dir\"\n","\n","os.chdir(ROOT_DIR)\n","\n","sys.path.append(os.path.join(ROOT_DIR, \"src\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3039,"status":"ok","timestamp":1742583170868,"user":{"displayName":"Rao Family","userId":"03614244497955458674"},"user_tz":-330},"id":"mwvUENTrP3Ow","outputId":"32351e1c-5a67-4d8f-9263-ce816e612ba4"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 3])\n"]}],"source":["#TO TEST MODEL'S OUTPUT SIZE/DIM\n","from model import ResNet20\n","import torch\n","\n","model = ResNet20()\n","sample_input = torch.randn(1, 1, 150, 150)  # Batch size 1, grayscale image (1,150,150)\n","print(model(sample_input).shape)  # Expected : torch.Size([1, 3])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elVJmT3Dz_wl"},"outputs":[],"source":["from npy import create_single_npy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TPdWX0ngzvr0"},"outputs":[],"source":["#TO SPEED UP THE DATA LOADING PROCESS, WE CONVERT 10K .npy files to a single .npy file, check ./src/npy.py for the function defn.\n","create_single_npy('proj_dir/dataset/train', 'proj_dir/dataset/train_data.npy')\n","create_single_npy('proj_dir/dataset/val', 'proj_dir/dataset/val_data.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VtktQRc8HgjN"},"outputs":[],"source":["data, labels = np.load(\"proj_dir/dataset/train_data.npy\", allow_pickle=True)\n","print(data.shape, labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9473,"status":"ok","timestamp":1742584899752,"user":{"displayName":"Rao Family","userId":"03614244497955458674"},"user_tz":-330},"id":"vlwk7cVfJysA","outputId":"280e5fb2-611b-4492-bed1-d3c46b76e3a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking TRAIN dataset structure:\n","Class: no\n","  - File: 8707.npy\n","  - Type: <class 'numpy.ndarray'>\n","  - Shape: (1, 150, 150)\n","--------------------------------------------------\n","Class: vort\n","  - File: 8961.npy\n","  - Type: <class 'numpy.ndarray'>\n","  - Shape: (1, 150, 150)\n","--------------------------------------------------\n","Class: sphere\n","  - File: 9299.npy\n","  - Type: <class 'numpy.ndarray'>\n","  - Shape: (1, 150, 150)\n","--------------------------------------------------\n","\n","Checking VALIDATION dataset structure:\n","Class: no\n","  - File: 1475.npy\n","  - Type: <class 'numpy.ndarray'>\n","  - Shape: (1, 150, 150)\n","--------------------------------------------------\n","Class: vort\n","  - File: 1310.npy\n","  - Type: <class 'numpy.ndarray'>\n","  - Shape: (1, 150, 150)\n","--------------------------------------------------\n","Class: sphere\n","  - File: 1419.npy\n","  - Type: <class 'numpy.ndarray'>\n","  - Shape: (1, 150, 150)\n","--------------------------------------------------\n"]}],"source":["import numpy as np\n","import os\n","\n","def check_npy_structure(base_path):\n","    classes = [\"no\", \"vort\", \"sphere\"]\n","    for cls in classes:\n","        folder_path = os.path.join(base_path, cls)\n","        npy_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.npy')]\n","\n","        if not npy_files:\n","            print(f\"No .npy files found in {folder_path}\")\n","            continue\n","\n","        sample_file = npy_files[0]  # Load the first file in the class folder\n","        sample_data = np.load(sample_file, allow_pickle=True)\n","\n","        print(f\"Class: {cls}\")\n","        print(f\"  - File: {os.path.basename(sample_file)}\")\n","        print(f\"  - Type: {type(sample_data)}\")\n","        print(f\"  - Shape: {sample_data.shape if isinstance(sample_data, np.ndarray) else 'Not a NumPy array'}\")\n","        print(\"-\" * 50)\n","\n","train_path = \"dir/Classification/dataset/train\"\n","val_path = \"dir/Classification/dataset/val\"\n","\n","print(\"Checking TRAIN dataset structure:\")\n","check_npy_structure(train_path)\n","\n","print(\"\\nChecking VALIDATION dataset structure:\")\n","check_npy_structure(val_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"k4YysVFPKglJ","outputId":"87c04518-ced6-4e4a-d91e-8871d1a6ee6c","collapsed":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved /content/drive/MyDrive/Hari/Evaluation/Classification/dataset/train_data.npz with shape (30000, 1, 150, 150), Labels shape (30000,)\n","Saved /content/drive/MyDrive/Hari/Evaluation/Classification/dataset/val_data.npz with shape (7500, 1, 150, 150), Labels shape (7500,)\n"]}],"source":["import numpy as np\n","import os\n","\n","def create_npz(input_dir, output_file):\n","    classes = [\"no\", \"vort\", \"sphere\"]\n","    all_data = []\n","    all_labels = []\n","\n","    label_map = {\"no\": 0, \"vort\": 1, \"sphere\": 2}\n","\n","    for cls in classes:\n","        folder_path = os.path.join(input_dir, cls)\n","        npy_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.npy')]\n","\n","        for file in npy_files:\n","            data = np.load(file)  # Shape: (1, 150, 150)\n","            all_data.append(data)\n","            all_labels.append(label_map[cls])\n","\n","    all_data = np.stack(all_data)  # Shape: (N, 1, 150, 150)\n","    all_labels = np.array(all_labels)  # Shape: (N,)\n","\n","    np.savez_compressed(output_file, images=all_data, labels=all_labels)\n","    print(f\"Saved {output_file} with shape {all_data.shape}, Labels shape {all_labels.shape}\")\n","\n","# Run this for both train and validation sets\n","train_dir = \"dir/Classification/dataset/train\"\n","val_dir = \"dir/Classification/dataset/val\"\n","\n","create_npz(train_dir, \"dir/Classification/dataset/train_data.npz\")\n","create_npz(val_dir, \"dir/Classification/dataset/val_data.npz\")\n"]},{"cell_type":"code","source":["train_data = np.load(\"dir/Classification/dataset/train_data.npz\")\n","X_train = train_data[\"images\"]  # Shape: (N, 1, 150, 150)\n","y_train = train_data[\"labels\"]  # Shape: (N,)\n","\n","val_data = np.load(\"dir/Classification/dataset/val_data.npz\")\n","X_val = val_data[\"images\"]\n","y_val = val_data[\"labels\"]\n","\n","print(f\"Train set: {X_train.shape}, Labels: {y_train.shape}\")\n","print(f\"Val set: {X_val.shape}, Labels: {y_val.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q10m9lOcW2jG","executionInfo":{"status":"ok","timestamp":1742588353286,"user_tz":-330,"elapsed":39654,"user":{"displayName":"Rao Family","userId":"03614244497955458674"}},"outputId":"6fb18916-459e-4fdd-8bcf-45f87d1bdc01","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Training set: (30000, 1, 150, 150), Labels: (30000,)\n","✅ Validation set: (7500, 1, 150, 150), Labels: (7500,)\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ANje3jBaYX-8rRaiyMgnZMBvrz2j6pNb","authorship_tag":"ABX9TyPu02wbXRtRhWbKKYPD5Jw1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}